{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivational Example (From Foundational NN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: [chollet](https://github.com/fchollet/deep-learning-with-python-notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 08:51:58.461661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Loads the MNIST dataset.\n",
      "\n",
      "This is a dataset of 60,000 28x28 grayscale images of the 10 digits,\n",
      "along with a test set of 10,000 images.\n",
      "More info can be found at the\n",
      "[MNIST homepage](http://yann.lecun.com/exdb/mnist/).\n",
      "\n",
      "Args:\n",
      "  path: path where to cache the dataset locally\n",
      "    (relative to `~/.keras/datasets`).\n",
      "\n",
      "Returns:\n",
      "  Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
      "\n",
      "**x_train**: uint8 NumPy array of grayscale image data with shapes\n",
      "  `(60000, 28, 28)`, containing the training data. Pixel values range\n",
      "  from 0 to 255.\n",
      "\n",
      "**y_train**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
      "  with shape `(60000,)` for the training data.\n",
      "\n",
      "**x_test**: uint8 NumPy array of grayscale image data with shapes\n",
      "  (10000, 28, 28), containing the test data. Pixel values range\n",
      "  from 0 to 255.\n",
      "\n",
      "**y_test**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
      "  with shape `(10000,)` for the test data.\n",
      "\n",
      "Example:\n",
      "\n",
      "```python\n",
      "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
      "assert x_train.shape == (60000, 28, 28)\n",
      "assert x_test.shape == (10000, 28, 28)\n",
      "assert y_train.shape == (60000,)\n",
      "assert y_test.shape == (10000,)\n",
      "```\n",
      "\n",
      "License:\n",
      "  Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
      "  which is a derivative work from original NIST datasets.\n",
      "  MNIST dataset is made available under the terms of the\n",
      "  [Creative Commons Attribution-Share Alike 3.0 license.](\n",
      "  https://creativecommons.org/licenses/by-sa/3.0/)\n",
      "\u001b[0;31mFile:\u001b[0m      /opt/miniconda3/envs/ml_python_2019/lib/python3.9/site-packages/keras/src/datasets/mnist.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "mnist.load_data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(x_train[2], cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Just your regular densely-connected NN layer.\n",
      "\n",
      "`Dense` implements the operation:\n",
      "`output = activation(dot(input, kernel) + bias)`\n",
      "where `activation` is the element-wise activation function\n",
      "passed as the `activation` argument, `kernel` is a weights matrix\n",
      "created by the layer, and `bias` is a bias vector created by the layer\n",
      "(only applicable if `use_bias` is `True`). These are all attributes of\n",
      "`Dense`.\n",
      "\n",
      "Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      "computes the dot product between the `inputs` and the `kernel` along the\n",
      "last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
      "For example, if input has dimensions `(batch_size, d0, d1)`, then we create\n",
      "a `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\n",
      "of the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n",
      "`batch_size * d0` such sub-tensors).  The output in this case will have\n",
      "shape `(batch_size, d0, units)`.\n",
      "\n",
      "Besides, layer attributes cannot be modified after the layer has been called\n",
      "once (except the `trainable` attribute).\n",
      "When a popular kwarg `input_shape` is passed, then keras will create\n",
      "an input layer to insert before the current layer. This can be treated\n",
      "equivalent to explicitly defining an `InputLayer`.\n",
      "\n",
      "Example:\n",
      "\n",
      ">>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
      ">>> model = tf.keras.models.Sequential()\n",
      ">>> model.add(tf.keras.Input(shape=(16,)))\n",
      ">>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
      ">>> # Now the model will take as input arrays of shape (None, 16)\n",
      ">>> # and output arrays of shape (None, 32).\n",
      ">>> # Note that after the first layer, you don't need to specify\n",
      ">>> # the size of the input anymore:\n",
      ">>> model.add(tf.keras.layers.Dense(32))\n",
      ">>> model.output_shape\n",
      "(None, 32)\n",
      "\n",
      "Args:\n",
      "    units: Positive integer, dimensionality of the output space.\n",
      "    activation: Activation function to use.\n",
      "        If you don't specify anything, no activation is applied\n",
      "        (ie. \"linear\" activation: `a(x) = x`).\n",
      "    use_bias: Boolean, whether the layer uses a bias vector.\n",
      "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      "    bias_initializer: Initializer for the bias vector.\n",
      "    kernel_regularizer: Regularizer function applied to\n",
      "        the `kernel` weights matrix.\n",
      "    bias_regularizer: Regularizer function applied to the bias vector.\n",
      "    activity_regularizer: Regularizer function applied to\n",
      "        the output of the layer (its \"activation\").\n",
      "    kernel_constraint: Constraint function applied to\n",
      "        the `kernel` weights matrix.\n",
      "    bias_constraint: Constraint function applied to the bias vector.\n",
      "\n",
      "Input shape:\n",
      "    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      "    The most common situation would be\n",
      "    a 2D input with shape `(batch_size, input_dim)`.\n",
      "\n",
      "Output shape:\n",
      "    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      "    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      "    the output would have shape `(batch_size, units)`.\n",
      "\u001b[0;31mFile:\u001b[0m           /opt/miniconda3/envs/ml_python_2019/lib/python3.9/site-packages/keras/src/layers/core/dense.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units=512,\n",
    "                       activation='relu',\n",
    "                       input_shape=(28 * 28,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units=10,\n",
    "                       activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_input = x_train.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_input.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_input.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_input = x_train_input.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_input = x_test.reshape((10000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_input = x_test_input.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encode the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3227 - accuracy: 0.9094\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1394 - accuracy: 0.9592\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0933 - accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0690 - accuracy: 0.9796\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0542 - accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0426 - accuracy: 0.9877\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0339 - accuracy: 0.9904\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0269 - accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0220 - accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0173 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x146e36f10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_input, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the model on test set or predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0631 - accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(x_test_input, \n",
    "                                     y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9815000295639038\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
